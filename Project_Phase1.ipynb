{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanaNiroomand/AI-Project-SUT-2025/blob/main/Project_Phase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0ff76a",
      "metadata": {
        "id": "6c0ff76a"
      },
      "source": [
        "\n",
        "<br>\n",
        "<font>\n",
        "<div dir=ltr align=center>\n",
        "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=150 height=150>\n",
        "<div dir=ltr align=center>\n",
        "<font color=0F5298 size=7>\n",
        "Â Â Â  Artificial Intelligence <br>\n",
        "<font color=2565AE size=5>\n",
        "Â Â Â  Computer Engineering Department <br>\n",
        "Â Â Â  Spring 2025<br>\n",
        "<font color=3C99D size=5>\n",
        "    Project-Phase1<br>\n",
        "    Image Segmentation<br>\n",
        "<font color=696880 size=4>\n",
        "Â Â Â  Shayan Baghayi Nejad-Armin Khosravi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "123da0cc",
      "metadata": {
        "id": "123da0cc"
      },
      "source": [
        "<font size=5 color=cyan> Names:\n",
        "\n",
        "Student Numbers:  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a4f949",
      "metadata": {
        "id": "69a4f949"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this Project, we will become familiar with UNet architecture, Attention mechanism, and Residual blocks with the help of which we will build UNet, AttentionUNet, and ResidualAttentionUnet from scratch using PyTorch framework. The built models will be evaluated by various metrics such as accuracy, Iou score, and Dice score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add2691c",
      "metadata": {
        "id": "add2691c"
      },
      "source": [
        "### Environment Setup\n",
        "\n",
        "Here you will find the required packages. Feel free to add the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a8c7abed",
      "metadata": {
        "id": "a8c7abed",
        "outputId": "d85bc6f9-7dad-49f0-9529-c575cfbe5671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a38d4c",
      "metadata": {
        "id": "b7a38d4c"
      },
      "source": [
        "### Hyperparameter Setting\n",
        "\n",
        "Place your hyperparameters' values in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "af2bade6",
      "metadata": {
        "id": "af2bade6"
      },
      "outputs": [],
      "source": [
        "# === Hyperparameters & Paths ===\n",
        "DATA_DIR = \"/content/drive/MyDrive/AI_Project_14032/massachusetts-roads-dataset\"  # root of dataset that contains 'tiff/train' and 'tiff/train_labels'\n",
        "IMAGE_SIZE = (256, 256)   # (W, H)\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 15\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec03182",
      "metadata": {
        "id": "2ec03182"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "Our task is to segment the [Massachusetts Road Dataset](https://www.kaggle.com/datasets/balraj98/massachusetts-roads-dataset). You can download this dataset by placing your API Token from kaggle in ```~/.kaggle/``` folder (Instructions can be found in the Kaggle website) and then running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4bd65cfb",
      "metadata": {
        "id": "4bd65cfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cb31fa-e8ce-4a9b-ebe3-0c645a5da49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â„¹ï¸ Ù‡ÛŒÚ† Ú©Ø´ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\n",
            "â„¹ï¸ Ø¯ÛŒØªØ§Ø³ØªÛŒ Ø¯Ø± Ú©Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\n",
            "ðŸ“‚ Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª: /kaggle/input/massachusetts-roads-dataset\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Ù…Ø³ÛŒØ± Ú©Ø´ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ KaggleHub Ø¯Ø± Colab\n",
        "kagglehub_cache = \"/root/.cache/kagglehub\"\n",
        "\n",
        "# Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ù¾Ø§Ú©Ø´ Ú©Ù†\n",
        "if os.path.exists(kagglehub_cache):\n",
        "    shutil.rmtree(kagglehub_cache)\n",
        "    print(\"âœ… ØªÙ…Ø§Ù… Ú©Ø´ KaggleHub Ù¾Ø§Ú© Ø´Ø¯.\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Ù‡ÛŒÚ† Ú©Ø´ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")\n",
        "\n",
        "# Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù¾ÙˆØ´Ù‡ Ø®Ø§Ù„ÛŒ Ø¨Ø³Ø§Ø² (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
        "os.makedirs(kagglehub_cache, exist_ok=True)\n",
        "\n",
        "dataset_cache_dir = \"/root/.cache/kagglehub/datasets/balraj98/massachusetts-roads-dataset\"\n",
        "\n",
        "# Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡ØŒ Ù¾Ø§Ú©Ø´ Ú©Ù†\n",
        "if os.path.exists(dataset_cache_dir):\n",
        "    shutil.rmtree(dataset_cache_dir)\n",
        "    print(\"âœ… Ù‡Ù…Ù‡ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø´Ø¯Ù‡ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Ø¯ÛŒØªØ§Ø³ØªÛŒ Ø¯Ø± Ú©Ø´ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\")\n",
        "\n",
        "# Ø­Ø§Ù„Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"balraj98/massachusetts-roads-dataset\")\n",
        "print(\"ðŸ“‚ Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ae940e",
      "metadata": {
        "id": "c6ae940e"
      },
      "source": [
        "If you are running on colab, it is highly recommended to save the dataset to your drive to avoid problems when disconnecting from runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7544f6e0",
      "metadata": {
        "id": "7544f6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22cf95f-1e22-4f28-fc91-c81eec4e1938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Google Drive Ú©Ù¾ÛŒ Ø´Ø¯ Ùˆ Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¨ÙˆØ¯ Ù¾Ø§Ú© Ø´Ø¯.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ù…Ø³ÛŒØ± Ù…Ø¨Ø¯Ø§ Ùˆ Ù…Ù‚ØµØ¯\n",
        "src = \"/kaggle/input/massachusetts-roads-dataset\"\n",
        "dst = \"/content/drive/MyDrive/AI_Project_14032/massachusetts-roads-dataset\"\n",
        "\n",
        "# Ø§Ú¯Ø± Ù…Ø³ÛŒØ± Ù…Ù‚ØµØ¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ú©Ø§Ù…Ù„ Ù¾Ø§Ú©Ø´ Ú©Ù†\n",
        "if os.path.exists(dst):\n",
        "    shutil.rmtree(dst)  # Ø­Ø°Ù Ú©Ù„ Ù¾ÙˆØ´Ù‡ Ø¨Ø§ Ù…Ø­ØªÙˆÛŒØ§ØªØ´\n",
        "\n",
        "# Ú©Ù¾ÛŒ Ú©Ù„ Ù¾ÙˆØ´Ù‡ Ø§Ø² Ù…Ø¨Ø¯Ø§ Ø¨Ù‡ Ù…Ù‚ØµØ¯\n",
        "shutil.copytree(src, dst)\n",
        "\n",
        "print(\"âœ… Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Google Drive Ú©Ù¾ÛŒ Ø´Ø¯ Ùˆ Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¨ÙˆØ¯ Ù¾Ø§Ú© Ø´Ø¯.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "978482b0",
      "metadata": {
        "id": "978482b0"
      },
      "source": [
        "### Loading Images\n",
        "\n",
        "Load the images and their corresponding masks in two separate lists. (The cell below might take some time to execute.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d1030509",
      "metadata": {
        "id": "d1030509"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "def load_images_and_masks(images_path, masks_path, image_size):\n",
        "    '''\n",
        "    Load and preprocess images and masks.\n",
        "    Returns images: (N,H,W,3) float32 in [0,1], masks: (N,H,W,1) float32 in {0,1}\n",
        "    '''\n",
        "    img_files = sorted([f for f in glob(os.path.join(images_path, '*')) if os.path.isfile(f)])\n",
        "    msk_files = sorted([f for f in glob(os.path.join(masks_path,  '*')) if os.path.isfile(f)])\n",
        "\n",
        "    if len(img_files) != len(msk_files):\n",
        "        msk_map = {os.path.splitext(os.path.basename(p))[0]: p for p in msk_files}\n",
        "        aligned_imgs, aligned_msks = [], []\n",
        "        for p in img_files:\n",
        "            stem = os.path.splitext(os.path.basename(p))[0]\n",
        "            if stem in msk_map:\n",
        "                aligned_imgs.append(p)\n",
        "                aligned_msks.append(msk_map[stem])\n",
        "        img_files, msk_files = aligned_imgs, aligned_msks\n",
        "\n",
        "    images, masks = [], []\n",
        "    for img_p, msk_p in zip(img_files, msk_files):\n",
        "        img = Image.open(img_p).convert('RGB').resize(image_size, Image.BILINEAR)\n",
        "        msk = Image.open(msk_p).convert('L').resize(image_size, Image.NEAREST)\n",
        "\n",
        "        img = np.asarray(img, dtype=np.float32) / 255.0\n",
        "        msk = np.asarray(msk, dtype=np.uint8)\n",
        "        msk = (msk > 0.0).astype(np.float32)\n",
        "        msk = np.expand_dims(msk, axis=-1)\n",
        "\n",
        "        images.append(img); masks.append(msk)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        raise RuntimeError(f'No image/mask pairs found under {images_path} / {masks_path}')\n",
        "\n",
        "    return np.stack(images, axis=0), np.stack(masks, axis=0)\n",
        "\n",
        "\n",
        "train_images_path = os.path.join(DATA_DIR, 'tiff', 'train')\n",
        "train_masks_path  = os.path.join(DATA_DIR, 'tiff', 'train_labels')\n",
        "\n",
        "val_images_path = os.path.join(DATA_DIR, 'tiff', 'val')\n",
        "val_masks_path  = os.path.join(DATA_DIR, 'tiff', 'val_labels')\n",
        "\n",
        "train_images, train_masks = load_images_and_masks(train_images_path, train_masks_path, IMAGE_SIZE)\n",
        "val_images,   val_masks   = load_images_and_masks(val_images_path,   val_masks_path,   IMAGE_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb001870",
      "metadata": {
        "id": "bb001870"
      },
      "source": [
        "### Data Visualization\n",
        "\n",
        "Display the images and their masks for several samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "76150940",
      "metadata": {
        "id": "76150940"
      },
      "outputs": [],
      "source": [
        "def visualize_images_and_masks(images, masks, n=5):\n",
        "    n = min(n, len(images))\n",
        "    plt.figure(figsize=(8, 4 * n))\n",
        "    for i in range(n):\n",
        "        plt.subplot(n, 2, 2*i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off'); plt.title('Image')\n",
        "        plt.subplot(n, 2, 2*i+2)\n",
        "        plt.imshow(masks[i].squeeze(), cmap='gray')\n",
        "        plt.axis('off'); plt.title('Mask')\n",
        "    plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef7624b",
      "metadata": {
        "id": "eef7624b"
      },
      "source": [
        "### Dataset Creation\n",
        "\n",
        "Finally, we will make the dataset using the list of images we have stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e22ec808",
      "metadata": {
        "id": "e22ec808"
      },
      "outputs": [],
      "source": [
        "class RoadDataset(Dataset):\n",
        "    def __init__(self, images, masks, image_transform=None, mask_transform=None):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        msk = self.masks[idx]\n",
        "        img_pil = Image.fromarray((img*255).astype(np.uint8))\n",
        "        msk_pil = Image.fromarray((msk.squeeze()*255).astype(np.uint8))\n",
        "\n",
        "        img_t = self.image_transform(img_pil) if self.image_transform else transforms.ToTensor()(img_pil)\n",
        "        msk_t = self.mask_transform(msk_pil)  if self.mask_transform  else transforms.ToTensor()(msk_pil)\n",
        "        msk_t = (msk_t > 0).float()\n",
        "        return img_t, msk_t\n",
        "\n",
        "image_transform = transforms.Compose([transforms.ToTensor()])\n",
        "mask_transform  = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = RoadDataset(train_images, train_masks, image_transform, mask_transform)\n",
        "val_dataset   = RoadDataset(val_images,   val_masks,   image_transform, mask_transform)\n",
        "\n",
        "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS)\n",
        "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c6ee17",
      "metadata": {
        "id": "89c6ee17"
      },
      "source": [
        "# UNet\n",
        "\n",
        "Before proceeding, it is necessary to understand the idea behind UNet. In order to avoid too much details in this notebook, you can read the complete paper for UNet from [this link](https://arxiv.org/pdf/1505.04597).\n",
        "\n",
        "The overall structure of UNet is provided in the image below.\n",
        "\n",
        "![UNet Architecture](https://viso.ai/wp-content/uploads/2024/04/unet-process.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e549668",
      "metadata": {
        "id": "2e549668"
      },
      "source": [
        "### Convolution Block\n",
        "\n",
        "Convolution block is used at each level of UNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1e971c7a",
      "metadata": {
        "id": "1e971c7a"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channel, out_channel, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4966b556",
      "metadata": {
        "id": "4966b556"
      },
      "source": [
        "### Up Convoluitional Block\n",
        "\n",
        "We use another block to upsample the latent vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ba57654e",
      "metadata": {
        "id": "ba57654e"
      },
      "outputs": [],
      "source": [
        "class UpConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super().__init__()\n",
        "        self.upconv = nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2)\n",
        "    def forward(self, x):\n",
        "        return self.upconv(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bcce31c",
      "metadata": {
        "id": "4bcce31c"
      },
      "source": [
        "### Complete UNet Structure\n",
        "\n",
        "Now using the ```ConvBlock``` and ```UpConvBlock``` you created, complete the UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6fd32f6f",
      "metadata": {
        "id": "6fd32f6f"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channel=3, out_channel=1, filter=[64,128,256,512]):\n",
        "        super().__init__()\n",
        "        f1,f2,f3,f4 = filter\n",
        "        self.enc1 = ConvBlock(in_channel, f1)\n",
        "        self.enc2 = ConvBlock(f1, f2)\n",
        "        self.enc3 = ConvBlock(f2, f3)\n",
        "        self.enc4 = ConvBlock(f3, f4)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.bottleneck = ConvBlock(f4, f4*2)\n",
        "\n",
        "        self.up4 = UpConvBlock(f4*2, f4); self.dec4 = ConvBlock(f4*2, f4)\n",
        "        self.up3 = UpConvBlock(f4, f3);   self.dec3 = ConvBlock(f3*2, f3)\n",
        "        self.up2 = UpConvBlock(f3, f2);   self.dec2 = ConvBlock(f2*2, f2)\n",
        "        self.up1 = UpConvBlock(f2, f1);   self.dec1 = ConvBlock(f1*2, f1)\n",
        "\n",
        "        self.out_conv = nn.Conv2d(f1, out_channel, 1)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(self.pool(x1))\n",
        "        x3 = self.enc3(self.pool(x2))\n",
        "        x4 = self.enc4(self.pool(x3))\n",
        "        xb = self.bottleneck(self.pool(x4))\n",
        "\n",
        "        d4 = self.up4(xb); d4 = torch.cat([d4, x4], dim=1); d4 = self.dec4(d4)\n",
        "        d3 = self.up3(d4); d3 = torch.cat([d3, x3], dim=1); d3 = self.dec3(d3)\n",
        "        d2 = self.up2(d3); d2 = torch.cat([d2, x2], dim=1); d2 = self.dec2(d2)\n",
        "        d1 = self.up1(d2); d1 = torch.cat([d1, x1], dim=1); d1 = self.dec1(d1)\n",
        "\n",
        "        out = self.out_conv(d1)\n",
        "        return self.act(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc57fb9",
      "metadata": {
        "id": "1cc57fb9"
      },
      "source": [
        "# Attention UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a5061be",
      "metadata": {
        "id": "2a5061be"
      },
      "source": [
        "### Attention Mechanism\n",
        "\n",
        "Attention UNet uses this mechanism to know what part the image is more important to attend to. You can read about this mechanism from [this link](https://arxiv.org/pdf/1706.03762). The Attention mechanism in UNet is described in [this paper](https://arxiv.org/pdf/1804.03999).\n",
        "\n",
        "\n",
        "![Attention](https://www.researchgate.net/publication/373655981/figure/fig3/AS:11431281186315360@1693879045519/Visualization-of-attention-blocks-reveals-their-functionality-While-the-self-attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bf440754",
      "metadata": {
        "id": "bf440754"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, f_g, f_l, f_int):\n",
        "        super().__init__()\n",
        "        self.w_g = nn.Sequential(\n",
        "            nn.Conv2d(f_g, f_int, 1, bias=True),\n",
        "            nn.BatchNorm2d(f_int)\n",
        "        )\n",
        "        self.w_x = nn.Sequential(\n",
        "            nn.Conv2d(f_l, f_int, 1, bias=True),\n",
        "            nn.BatchNorm2d(f_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(f_int, 1, 1, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        psi = self.act(self.w_g(g) + self.w_x(x))\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19439b32",
      "metadata": {
        "id": "19439b32"
      },
      "source": [
        "Now use the ```AttentionBlock``` to inherit [Attention UNet](https://arxiv.org/pdf/1804.03999) from UNet.\n",
        "\n",
        "![Attention UNet](https://www.researchgate.net/publication/347344899/figure/fig6/AS:971357475069952@1608601077414/The-architecture-of-Attention-U-Net-Attention-gate-selects-features-by-using-the.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b30d6840",
      "metadata": {
        "id": "b30d6840"
      },
      "outputs": [],
      "source": [
        "class AttentionUNet(UNet):\n",
        "    def __init__(self, in_channel=3, out_channel=1, filter_sizes=[64,128,256,512]):\n",
        "        super().__init__(in_channel, out_channel, filter_sizes)\n",
        "        f1,f2,f3,f4 = filter_sizes\n",
        "        self.att4 = AttentionBlock(f4, f4, f4//2)\n",
        "        self.att3 = AttentionBlock(f3, f3, f3//2)\n",
        "        self.att2 = AttentionBlock(f2, f2, f2//2)\n",
        "        self.att1 = AttentionBlock(f1, f1, f1//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(self.pool(x1))\n",
        "        x3 = self.enc3(self.pool(x2))\n",
        "        x4 = self.enc4(self.pool(x3))\n",
        "        xb = self.bottleneck(self.pool(x4))\n",
        "\n",
        "        d4 = self.up4(xb); x4a = self.att4(d4, x4); d4 = self.dec4(torch.cat([d4, x4a], dim=1))\n",
        "        d3 = self.up3(d4); x3a = self.att3(d3, x3); d3 = self.dec3(torch.cat([d3, x3a], dim=1))\n",
        "        d2 = self.up2(d3); x2a = self.att2(d2, x2); d2 = self.dec2(torch.cat([d2, x2a], dim=1))\n",
        "        d1 = self.up1(d2); x1a = self.att1(d1, x1); d1 = self.dec1(torch.cat([d1, x1a], dim=1))\n",
        "\n",
        "        out = self.out_conv(d1)\n",
        "        return self.act(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3194d5",
      "metadata": {
        "id": "1a3194d5"
      },
      "source": [
        "# Residual Attention UNet\n",
        "\n",
        "We will add residual blocks to the attention for better gradient flow. You can read more about residual blocks [here](https://arxiv.org/pdf/1512.03385).\n",
        "\n",
        "<img src=\"https://dfzljdn9uc3pi.cloudfront.net/2023/cs-1302/1/fig-1-full.png\" width=\"400\" alt=\"ResUNet Architecture\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a009671f",
      "metadata": {
        "id": "a009671f"
      },
      "outputs": [],
      "source": [
        "class ResidualConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channel, out_channel, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "        )\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "        ) if in_channel != out_channel else nn.Identity()\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.conv2(y)\n",
        "        return self.act(y + self.shortcut(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5739ce",
      "metadata": {
        "id": "bf5739ce"
      },
      "source": [
        "Use ```ResidualConvBlock``` to construct Residual Attention Unet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ac0b6428",
      "metadata": {
        "id": "ac0b6428"
      },
      "outputs": [],
      "source": [
        "class ResidualAttentionUNet(AttentionUNet):\n",
        "    def __init__(self, in_channel=3, out_channel=1, filter_sizes=[64,128,256,512]):\n",
        "        super().__init__(in_channel, out_channel, filter_sizes)\n",
        "        f1,f2,f3,f4 = filter_sizes\n",
        "        self.enc1 = ResidualConvBlock(in_channel, f1)\n",
        "        self.enc2 = ResidualConvBlock(f1, f2)\n",
        "        self.enc3 = ResidualConvBlock(f2, f3)\n",
        "        self.enc4 = ResidualConvBlock(f3, f4)\n",
        "        self.bottleneck = ResidualConvBlock(f4, f4*2)\n",
        "        self.dec4 = ResidualConvBlock(f4*2, f4)\n",
        "        self.dec3 = ResidualConvBlock(f3*2, f3)\n",
        "        self.dec2 = ResidualConvBlock(f2*2, f2)\n",
        "        self.dec1 = ResidualConvBlock(f1*2, f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce7e105",
      "metadata": {
        "id": "9ce7e105"
      },
      "source": [
        "# Training\n",
        "\n",
        "Now it is time to train the model on training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa6a47a",
      "metadata": {
        "id": "4aa6a47a"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "We will be using the sum of [Dice Score](https://oecd.ai/en/catalogue/metrics/dice-score#:~:text=The%20Dice%20score%20is%20calculated,sizes%20of%20the%20two%20sets.), [Iou Score](https://www.v7labs.com/blog/intersection-over-union-guide), and Binary Cross Entropy as loss function. You can read about the mentioned scores in the provided links.\n",
        "\n",
        "<font color=cyan><b> Note: Do Not Change The ```OverallLoss``` Function as it is used for measuring you model's performance.</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f0966ba5",
      "metadata": {
        "id": "f0966ba5"
      },
      "outputs": [],
      "source": [
        "### DICE LOSS\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "    def forward(self, pred, real):\n",
        "        pred = pred.contiguous(); real = real.contiguous()\n",
        "        inter = (pred*real).sum(dim=(2,3))\n",
        "        denom = pred.sum(dim=(2,3)) + real.sum(dim=(2,3))\n",
        "        dice = (2*inter + self.smooth) / (denom + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "class IouLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__(); self.smooth = smooth\n",
        "    def forward(self, pred, real):\n",
        "        pred = pred.contiguous(); real = real.contiguous()\n",
        "        inter = (pred*real).sum(dim=(2,3))\n",
        "        union = pred.sum(dim=(2,3)) + real.sum(dim=(2,3)) - inter\n",
        "        iou = (inter + self.smooth) / (union + self.smooth)\n",
        "        return 1 - iou.mean()\n",
        "\n",
        "class OverallLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.dice_loss = DiceLoss(smooth)\n",
        "        self.iou_loss  = IouLoss(smooth)\n",
        "        self.bce_loss  = nn.BCELoss()\n",
        "    def forward(self, pred, real):\n",
        "        dice = self.dice_loss(pred, real)\n",
        "        iou  = self.iou_loss(pred, real)\n",
        "        bce  = self.bce_loss(pred, real)\n",
        "        return dice, iou, bce, dice+iou+bce\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b23e9266",
      "metadata": {
        "id": "b23e9266"
      },
      "source": [
        "### Training Epoch\n",
        "\n",
        "Complete the function below to train the model for one epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "538edeee",
      "metadata": {
        "id": "538edeee"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, data_loader, scheduler=None, device='cuda'):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for imgs, masks in tqdm(data_loader, desc='Train', leave=False):\n",
        "        imgs = imgs.to(device); masks = masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(imgs)\n",
        "        _, _, _, loss = criterion(pred, masks)\n",
        "        loss.backward(); optimizer.step()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        total += loss.item()\n",
        "    return total / max(1, len(data_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df64e4e7",
      "metadata": {
        "id": "df64e4e7"
      },
      "source": [
        "Design a function for evaluation after each training phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0a63f31b",
      "metadata": {
        "id": "0a63f31b"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, criterion, data_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    total = 0.0; iou_s = 0.0; dice_s = 0.0\n",
        "    with torch.inference_mode():\n",
        "        for imgs, masks in tqdm(data_loader, desc='Eval', leave=False):\n",
        "            imgs = imgs.to(device); masks = masks.to(device)\n",
        "            pred = model(imgs)\n",
        "            dice_l, iou_l, bce_l, overall_l = criterion(pred, masks)\n",
        "            total += overall_l.item()\n",
        "            iou_s  += 1 - iou_l.item()\n",
        "            dice_s += 1 - dice_l.item()\n",
        "    n = max(1, len(data_loader))\n",
        "    return total/n, iou_s/n, dice_s/n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223a8cc5",
      "metadata": {
        "id": "223a8cc5"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "### UNet  \n",
        "Create an instance of UNet and train it. Then report the results.  \n",
        "\n",
        "<b><font color=red>Note: your models need to satisfy below conditions to get complete score.</font></b>\n",
        "\n",
        "<table style=\"width: 100%; font-size: 18px; border-collapse: collapse; margin: 15px 0;\">\n",
        "  <tr>\n",
        "    <th style=\"text-align: left; padding: 8px; border-bottom: 2px solid #ddd;\">Model</th>\n",
        "    <th style=\"text-align: right; padding: 8px; border-bottom: 2px solid #ddd;\">Validation Loss</th>\n",
        "    <th style=\"text-align: right; padding: 8px; border-bottom: 2px solid #ddd;\">Iou Score</th>\n",
        "    <th style=\"text-align: right; padding: 8px; border-bottom: 2px solid #ddd;\">Dice Score</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">UNet</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&lt; 1.0</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&gt; 0.5</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&gt; 0.6</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Attention UNet</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&lt; 0.9</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&gt; 0.6</td>\n",
        "    <td style=\"text-align: right; padding: 8px; border-bottom: 1px solid #ddd;\">&gt; 0.65</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 8px;\">Residual Attention UNet</td>\n",
        "    <td style=\"text-align: right; padding: 8px;\">&lt; 0.8</td>\n",
        "    <td style=\"text-align: right; padding: 8px;\">&gt; 0.65</td>\n",
        "    <td style=\"text-align: right; padding: 8px;\">&gt; 0.7</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "400db6ae",
      "metadata": {
        "id": "400db6ae",
        "outputId": "db61d00f-d491-4670-fa7e-803a3d07af2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/15: Train Loss: 1.95 | Val Loss: 1.55 | Iou Score: 0.26 | Dice Score: 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2/15: Train Loss: 1.40 | Val Loss: 1.26 | Iou Score: 0.38 | Dice Score: 0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3/15: Train Loss: 1.26 | Val Loss: 1.19 | Iou Score: 0.42 | Dice Score: 0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4/15: Train Loss: 1.20 | Val Loss: 1.17 | Iou Score: 0.43 | Dice Score: 0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 5/15: Train Loss: 1.17 | Val Loss: 1.06 | Iou Score: 0.47 | Dice Score: 0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 6/15: Train Loss: 1.15 | Val Loss: 1.06 | Iou Score: 0.47 | Dice Score: 0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 7/15: Train Loss: 1.13 | Val Loss: 1.02 | Iou Score: 0.49 | Dice Score: 0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 8/15: Train Loss: 1.12 | Val Loss: 1.04 | Iou Score: 0.49 | Dice Score: 0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 9/15: Train Loss: 1.11 | Val Loss: 0.98 | Iou Score: 0.51 | Dice Score: 0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10/15: Train Loss: 1.10 | Val Loss: 0.97 | Iou Score: 0.51 | Dice Score: 0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 11/15: Train Loss: 1.09 | Val Loss: 1.00 | Iou Score: 0.51 | Dice Score: 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 12/15: Train Loss: 1.08 | Val Loss: 0.95 | Iou Score: 0.52 | Dice Score: 0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 13/15: Train Loss: 1.07 | Val Loss: 0.96 | Iou Score: 0.52 | Dice Score: 0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 14/15: Train Loss: 1.06 | Val Loss: 0.98 | Iou Score: 0.51 | Dice Score: 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 15/15: Train Loss: 1.06 | Val Loss: 0.95 | Iou Score: 0.53 | Dice Score: 0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "unet = UNet().to(device)\n",
        "criterion = OverallLoss()\n",
        "# You can use other optimizers or Adam optimizer with customized weight decay, b1, or b2\n",
        "optimizer = Adam(unet.parameters(), lr=LR)\n",
        "# Add a scheduler if you like\n",
        "\n",
        "best_loss = 100.0\n",
        "for i in range(NUM_EPOCHS):\n",
        "    train_loss = train_one_epoch(unet, optimizer, criterion, train_loader)\n",
        "    val_loss, iou_score, dice_score = evaluate_model(unet, criterion, val_loader)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(unet.state_dict(), \"best_unet.pth\")\n",
        "\n",
        "    print(f\"Iteration {i+1}/{NUM_EPOCHS}: \"\n",
        "          f\"Train Loss: {train_loss:.2f} | \"\n",
        "          f\"Val Loss: {val_loss:.2f} | \"\n",
        "          f\"Iou Score: {iou_score:.2f} | \"\n",
        "          f\"Dice Score: {dice_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23109259",
      "metadata": {
        "id": "23109259"
      },
      "source": [
        "Now do the same for Attention UNet and Reidual Attention UNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b74e7bb",
      "metadata": {
        "id": "3b74e7bb",
        "outputId": "f48e2dab-de8b-4185-f1e3-d71179b3703e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/15: Train Loss: 1.97 | Val Loss: 1.49 | Iou Score: 0.27 | Dice Score: 0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2/15: Train Loss: 1.40 | Val Loss: 1.26 | Iou Score: 0.39 | Dice Score: 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3/15: Train Loss: 1.24 | Val Loss: 1.07 | Iou Score: 0.47 | Dice Score: 0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4/15: Train Loss: 1.19 | Val Loss: 1.01 | Iou Score: 0.49 | Dice Score: 0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 131/139 [01:08<00:04,  1.92it/s]"
          ]
        }
      ],
      "source": [
        "attention_unet = AttentionUNet().to(device)\n",
        "criterion = OverallLoss()\n",
        "# You can use other optimizers or Adam optimizer with customized weight decay, b1, or b2\n",
        "optimizer = Adam(attention_unet.parameters(), lr=LR)\n",
        "\n",
        "best_loss = 100.0\n",
        "for i in range(NUM_EPOCHS):\n",
        "    train_loss = train_one_epoch(attention_unet, optimizer, criterion, train_loader)\n",
        "    val_loss, iou_score, dice_score = evaluate_model(attention_unet, criterion, val_loader)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(attention_unet.state_dict(), \"best_attention_unet.pth\")\n",
        "\n",
        "    print(f\"Iteration {i+1}/{NUM_EPOCHS}: \"\n",
        "          f\"Train Loss: {train_loss:.2f} | \"\n",
        "          f\"Val Loss: {val_loss:.2f} | \"\n",
        "          f\"Iou Score: {iou_score:.2f} | \"\n",
        "          f\"Dice Score: {dice_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293ad90a",
      "metadata": {
        "id": "293ad90a"
      },
      "source": [
        "For Residual Attention UNet, plot the changes in train and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64e512b",
      "metadata": {
        "id": "f64e512b"
      },
      "outputs": [],
      "source": [
        "resattn_unet = ResidualAttentionUNet().to(device)\n",
        "criterion = OverallLoss()\n",
        "# You can use other optimizers or Adam optimizer with customized weight decay, b1, or b2\n",
        "optimizer = Adam(resattn_unet.parameters(), lr=LR)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_loss = 100.0\n",
        "for i in range(NUM_EPOCHS):\n",
        "    train_loss = train_one_epoch(resattn_unet, optimizer, criterion, train_loader)\n",
        "    val_loss, iou_score, dice_score = evaluate_model(resattn_unet, criterion, val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        torch.save(resattn_unet.state_dict(), \"best_residual_attention_unet.pth\")\n",
        "\n",
        "    print(f\"Iteration {i+1}/{NUM_EPOCHS}: \"\n",
        "          f\"Train Loss: {train_loss:.2f} | \"\n",
        "          f\"Val Loss: {val_loss:.2f} | \"\n",
        "          f\"Iou Score: {iou_score:.2f} | \"\n",
        "          f\"Dice Score: {dice_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77aff22a",
      "metadata": {
        "id": "77aff22a"
      },
      "source": [
        "Now Visualize losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c313615f",
      "metadata": {
        "id": "c313615f",
        "outputId": "7249715b-72bb-40f4-908b-3dbcffc5b9de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the losses\n",
        "if 'train_losses' in globals() and 'val_losses' in globals() and len(train_losses) and len(val_losses):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_losses, label='Train'); plt.plot(val_losses, label='Val')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Training vs Validation Loss'); plt.show()\n",
        "else:\n",
        "    print(\"Run the ResidualAttentionUNet training cell to populate train_losses/val_losses.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f3e2e4",
      "metadata": {
        "id": "69f3e2e4"
      },
      "source": [
        "### Prediction Visualisation\n",
        "\n",
        "Display several images, their masks, and the predicted mask by your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "114b323d",
      "metadata": {
        "id": "114b323d"
      },
      "outputs": [],
      "source": [
        "def visualize_image_mask_prediction(images, masks, predictions, n=5):\n",
        "    n = min(n, len(images))\n",
        "    plt.figure(figsize=(12, 4*n))\n",
        "    for i in range(n):\n",
        "        plt.subplot(n,3,3*i+1); plt.imshow(images[i]); plt.axis('off'); plt.title('Image')\n",
        "        plt.subplot(n,3,3*i+2); plt.imshow(masks[i].squeeze(), cmap='gray'); plt.axis('off'); plt.title('Mask')\n",
        "        pr = predictions[i]\n",
        "        pr = pr.squeeze()\n",
        "        if pr.ndim == 3: pr = pr[0]\n",
        "        plt.subplot(n,3,3*i+3); plt.imshow((pr>=0.5).astype(np.float32), cmap='gray'); plt.axis('off'); plt.title('Prediction')\n",
        "    plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c4c0d0",
      "metadata": {
        "id": "b8c4c0d0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}